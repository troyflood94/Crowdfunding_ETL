# Crowdfunding ETL
![image](https://github.com/user-attachments/assets/516111a5-5ab8-4be1-b1c8-dbb1cd14e8c4)

# Team Members
Jason Crespo

Troy Flood

Rudra Naik

Raphael Sheikh

# Introduction
For the ETL mini project, we will work to practice building an ETL pipeline using Python, Pandas, and either Python dictionary methods or regular expressions to extract and transform the data. After we transform the data, we'll create four CSV files and use the CSV file data to create an ERD and a table schema. Finally, weâ€™ll upload the CSV file data into a Postgres database.

ETL (Extract, Transform & Load) is a foundational skill. In the real world, data is everywhere and often scattered across multiple sources, and it can be messy. Understanding how to extract, load, and transform data is a critical concept as it enables you to have clean, up-to-date, and accurate data. It empowers you to become an expert in your data by allowing you to manipulate data types, fix formatting issues, and create additional columns to enrich and gain meaningful insights from your data.

# ERD
![image](https://github.com/user-attachments/assets/85c9f0d4-7989-47a5-a53d-31960c023556)

# Conclusion
In conclusion, this ETL mini project will equip you with essential skills in data extraction, transformation, and loading using Python and Pandas. By working through the process of cleaning and organizing data from multiple sources, creating CSV files, developing an ERD and table schema, and uploading data to a Postgres database, you will gain a comprehensive understanding of ETL processes. This knowledge is critical for ensuring accurate and insightful data analysis, making you proficient in managing and manipulating data effectively.
